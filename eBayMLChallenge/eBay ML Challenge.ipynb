{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "859753a2",
   "metadata": {},
   "source": [
    "<h1>eBay Machine Learning Challenge: <span style=\"color: blue\">Vilqueso</span></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a41d08",
   "metadata": {},
   "source": [
    "<p> <b>Goal:</b> Predict delivery date </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb01d79c",
   "metadata": {},
   "source": [
    "Dataset Columns and Starting Assumptions\n",
    "\n",
    "<ul>\n",
    "    <li><i>payment_datetime:</i> Can predict delivery days instead of date and then add prediction to this date <b>[KEEP]</b></li>\n",
    "    <li><i>acceptance_scan_timestamp:</i> Can be used in order to calculate a synthetic feature \"actual_handling_days\"<b> [KEEP]</b></li>\n",
    "    <li><i>b2c_c2c:</i> This is only relevent to predicting handling part of delivery <b>[DROP]</b></li>\n",
    "    <li><i>seller_id:</i> This is only relevant to predicting handling part of delivery <b>[DROP]</b></li>\n",
    "    <li><i>declared_handling_days:</i> We already established a \"actual_handling_days\" feature <b>[DROP]</b></li>\n",
    "    <li><i>shipment_method_id:</i> This could be useful for shipping days part of delivery <b>[KEEP]</b></li>\n",
    "    <li><i>shipping_fee:</i> Given that seller decides this fee, it is irrelevant to carrier <b>[DROP]</b></li>\n",
    "    <li><i>carrier_min_estimate:</i> This could be useful for shipping days part of delivery <b>[KEEP]</b></li>\n",
    "    <li><i>carrier_max_estimate:</i> This could be useful for shipping days part of delivery <b>[KEEP]</b></li>\n",
    "    <li><i>item_zip:</i> This could be useful for shipping days part of delivery if used with buyer_zip <b>[KEEP]</b></li>\n",
    "    <li><i>buyer_zip:</i> This could be useful for shipping days part of delivery if used with item_zip <b>[KEEP]</b></li>\n",
    "    <li><i>category_id:</i> It is possible that some categories such as furniture, take longer on average <b>[KEEP]</b></li>\n",
    "    <li><i>item_price:</i> Price is irrelevant to delivery day as a phone could be worth more than a sofa <b>[DROP]</b></li>\n",
    "    <li><i>quantity:</i> Quantity is only relevant to handling days. <b>[DROP]</b></li>\n",
    "    <li><i>delivery_date:</i> Labels <b>[KEEP]</b></li>\n",
    "    <li><i>weight:</i> Can be crossed with weight_units to get all instances in same units <b>[KEEP]</b></li>\n",
    "    <li><i>weight_units:</i> Change cat 2 to 2.2 in order to preform feature cross to change kg to lbs <b>[KEEP]</b></li>\n",
    "    <li><i>package_size:</i> Smaller packages are usually easier to ship <b>[KEEP]</b></li>\n",
    "    <li><i>record_number:</i> Only needed for quiz set <b>[KEEP FOR QUIZ]</b></li>\n",
    "</ul> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5e0980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47daa4f7",
   "metadata": {},
   "source": [
    "# Data Cleaning & Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d1fda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving data\n",
    "relevant_features = {\n",
    "                    'payment_datetime': 'object',\n",
    "                    'acceptance_scan_timestamp': 'object',\n",
    "                    'shipment_method_id': 'int16',\n",
    "                    'carrier_min_estimate': 'int16',\n",
    "                    'carrier_max_estimate': 'int16',\n",
    "                    'item_zip': 'object',\n",
    "                    'buyer_zip': 'object', \n",
    "                    #'delivery_date': 'object',\n",
    "                    #'weight': 'float32',\n",
    "                    #'weight_units': 'int8',\n",
    "                    #'package_size': 'category',\n",
    "                    }\n",
    "\n",
    "#data = pd.read_csv('train.tsv', sep='\\t', usecols=relevant_features.keys(), dtype=relevant_features)\n",
    "quiz = pd.read_csv('quiz.tsv', sep='\\t', usecols=relevant_features.keys(), dtype=relevant_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c287f371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to change time objects to just date of datetime\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DateConverter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, have_labels=True):\n",
    "        self.cols = [\n",
    "                     'acceptance_scan_timestamp', \n",
    "                     'payment_datetime',\n",
    "                     'delivery_date',\n",
    "                    ]\n",
    "        if not have_labels:\n",
    "            self.cols.pop()\n",
    "            \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        for col in self.cols: \n",
    "            X[col] = X[col].astype(str)\n",
    "            X[col] = X[col].str[:10]\n",
    "            X[col] = pd.to_datetime(X[col])\n",
    "            \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffc8374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add actual_handling_days / delivery_days\n",
    "class DatesToDays(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, have_labels=True):\n",
    "        self.have_labels = have_labels\n",
    "        \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X['actual_handling_days'] = X['acceptance_scan_timestamp'] - X['payment_datetime']\n",
    "        X['actual_handling_days'] = X['actual_handling_days'].dt.days\n",
    "        X['actual_handling_days'] = X['actual_handling_days'].astype('int16')\n",
    "        #X.drop(columns=['acceptance_scan_timestamp'], inplace=True)\n",
    "        \n",
    "        if self.have_labels:\n",
    "            X['delivery_days'] = X['delivery_date'] - X['payment_datetime']\n",
    "            X['delivery_days'] = X['delivery_days'].dt.days\n",
    "            X['delivery_days'] = X['delivery_days'].astype('int16')\n",
    "            X.drop(columns=['delivery_date', 'payment_datetime'], inplace=True)\n",
    "            \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36429f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert all weight to lbs\n",
    "class NormalizeWeights(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X['weight_units'].replace(to_replace=2, value=2.2)\n",
    "        \n",
    "        X['weight_lbs'] = X['weight'] * X['weight_units']\n",
    "        X['weight_lbs'].astype('float32')\n",
    "        X.drop(columns=['weight', 'weight_units'], inplace=True)\n",
    "        \n",
    "        X['weight_lbs'] = (X['weight_lbs'] - X['weight_lbs'].min()) / (X['weight_lbs'].max() - X['weight_lbs'].min())\n",
    "        X['weight_lbs'] = X['weight_lbs'].astype('float32')\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f600dd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to label zips based on their first digit\n",
    "class ZipsToBin(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, can_drop_unacceptable=True):\n",
    "        self.acceptable = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "        self.can_drop = can_drop_unacceptable\n",
    "        \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X['item_zip'] = X['item_zip'].astype(str)\n",
    "        X['item_zip'] = X['item_zip'].str[0]\n",
    "\n",
    "        X['buyer_zip'] = X['buyer_zip'].astype(str)\n",
    "        X['buyer_zip'] = X['buyer_zip'].str[0]\n",
    "        \n",
    "        if self.can_drop:\n",
    "            X = X[X['item_zip'].isin(self.acceptable)]\n",
    "            X = X[X['buyer_zip'].isin(self.acceptable)]\n",
    "        else:\n",
    "            X.loc[~X.buyer_zip.isin(self.acceptable), 'buyer_zip'] = '4'\n",
    "            X.loc[~X.item_zip.isin(self.acceptable), 'item_zip'] = '4'\n",
    "            \n",
    "        X['item_zip'] = X['item_zip'].astype('int8')\n",
    "        X['buyer_zip'] = X['buyer_zip'].astype('int8')\n",
    "        \n",
    "        bins = [-1, 4, 7, 8, 9]\n",
    "        labels = ['east', 'central', 'mountain', 'pacific']\n",
    "        X['item_zip'] = pd.cut(X['item_zip'], bins, labels=labels)\n",
    "        X['buyer_zip'] = pd.cut(X['buyer_zip'], bins, labels=labels)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c525e556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert all package_size to ordinal labels\n",
    "class PackageSizeToNum(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.astype('object')\n",
    "        X.loc[X.package_size == 'LETTER', 'package_size'] = 0\n",
    "        X.loc[X.package_size == 'PACKAGE_THICK_ENVELOPE', 'package_size'] = 1\n",
    "        X.loc[X.package_size == 'LARGE_ENVELOPE', 'package_size'] = 2\n",
    "        X.loc[X.package_size == 'LARGE_PACKAGE', 'package_size'] = 3\n",
    "        X.loc[X.package_size == 'EXTRA_LARGE_PACKAGE', 'package_size'] = 4\n",
    "        X.loc[X.package_size == 'VERY_LARGE_PACKAGE', 'package_size'] = 5\n",
    "        X.loc[X.package_size == 'NONE', 'package_size'] = 3\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ab37a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert all weight to lbs\n",
    "class LabelEncodeCat(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = pd.concat([X, pd.get_dummies(X['shipment_method_id'], prefix='shipment_method_id', drop_first=False)], axis=1)\n",
    "        \n",
    "        X['timezone_difference'] = 0\n",
    "        \n",
    "        X.loc[(X['item_zip'] == 'east') & (X['buyer_zip'] == 'central'), 'timezone_difference'] = 1\n",
    "        X.loc[(X['item_zip'] == 'central') & (X['buyer_zip'] == 'east'), 'timezone_difference'] = 1\n",
    "        \n",
    "        X.loc[(X['item_zip'] == 'pacific') & (X['buyer_zip'] == 'mountain'), 'timezone_difference'] = 1\n",
    "        X.loc[(X['item_zip'] == 'mountain') & (X['buyer_zip'] == 'pacific'), 'timezone_difference'] = 1\n",
    "        \n",
    "        X.loc[(X['item_zip'] == 'mountain') & (X['buyer_zip'] == 'central'), 'timezone_difference'] = 1\n",
    "        X.loc[(X['item_zip'] == 'central') & (X['buyer_zip'] == 'mountain'), 'timezone_difference'] = 1\n",
    "        \n",
    "        X.loc[(X['item_zip'] == 'central') & (X['buyer_zip'] == 'pacific'), 'timezone_difference'] = 2\n",
    "        X.loc[(X['item_zip'] == 'pacific') & (X['buyer_zip'] == 'central'), 'timezone_difference'] = 2\n",
    "        \n",
    "        X.loc[(X['item_zip'] == 'east') & (X['buyer_zip'] == 'mountain'), 'timezone_difference'] = 2\n",
    "        X.loc[(X['item_zip'] == 'mountain') & (X['buyer_zip'] == 'east'), 'timezone_difference'] = 2\n",
    "        \n",
    "        X.loc[(X['item_zip'] == 'pacific') & (X['buyer_zip'] == 'east'), 'timezone_difference'] = 3\n",
    "        X.loc[(X['item_zip'] == 'east') & (X['buyer_zip'] == 'pacific'), 'timezone_difference'] = 3\n",
    "        \n",
    "        \n",
    "        X.drop(columns=['shipment_method_id', #'shipment_method_id_24'\n",
    "                        'item_zip', 'buyer_zip'], inplace=True)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0023f10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that uses max and min estimate to add bound features\n",
    "class AddBounds(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X['top_bound'] = X['carrier_max_estimate'] + X['actual_handling_days']\n",
    "        X['bot_bound'] = X['carrier_min_estimate'] + X['actual_handling_days']\n",
    "        \n",
    "        X.drop(columns=['carrier_min_estimate', 'carrier_max_estimate'], inplace=True)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd905610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove invalid dates from set\n",
    "class RemoveInvalidDates(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X[X['delivery_days'] > 0]\n",
    "        X = X[X['actual_handling_days'] > 0]\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae8aa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add calendar days onto carrier estimate\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "class OffDaysFromCarrier(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        cal = calendar() \n",
    "        holidays = cal.holidays(start=X['acceptance_scan_timestamp'].min(), end=X['acceptance_scan_timestamp'].max())\n",
    "                \n",
    "        temp = X['carrier_min_estimate'].apply(lambda x: pd.Timedelta(x, unit='D'))\n",
    "        X['min_off_days'] = X['acceptance_scan_timestamp'] + temp\n",
    "        temp = X['carrier_max_estimate'].apply(lambda x: pd.Timedelta(x, unit='D'))\n",
    "        X['max_off_days'] = X['acceptance_scan_timestamp'] + temp\n",
    "\n",
    "        X['min_off_days'] = [(pd.date_range(x, y).isin(holidays) | pd.date_range(x, y).weekday.isin([5, 6])).sum() for x, y in zip(X.acceptance_scan_timestamp, X.min_off_days)]\n",
    "        X['max_off_days'] = [(pd.date_range(x, y).isin(holidays) | pd.date_range(x, y).weekday.isin([5, 6])).sum() for x, y in zip(X.acceptance_scan_timestamp, X.max_off_days)]\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb00f2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "training_pipeline = Pipeline([\n",
    "                    ('date_converter', DateConverter()),\n",
    "                    ('date_to_days', DatesToDays()),\n",
    "                    #('weight_normalize', NormalizeWeights()),\n",
    "                    ('bin_zip', ZipsToBin()),\n",
    "                    #('package_to_num', PackageSizeToNum()),\n",
    "                    ('label_encode_cat', LabelEncodeCat()),\n",
    "                    #('bound_features', AddBounds()),\n",
    "                    ('remove_invalid_dates', RemoveInvalidDates()),\n",
    "                    ('weekends_holidays', OffDaysFromCarrier()),\n",
    "                    ])\n",
    "\n",
    "prediction_pipeline = Pipeline([\n",
    "                     ('date_converter', DateConverter(have_labels=False)),\n",
    "                     ('date_to_days', DatesToDays(have_labels=False)),\n",
    "                     #('weight_normalize', NormalizeWeights()),\n",
    "                     ('bin_zip', ZipsToBin(can_drop_unacceptable=False)),\n",
    "                     #('package_to_num', PackageSizeToNum()),\n",
    "                     ('label_encode_cat', LabelEncodeCat()),\n",
    "                     #('bound_features', AddBounds()),\n",
    "                     ('weekends_holidays', OffDaysFromCarrier()),\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48e9cd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transforming training data\n",
    "data = training_pipeline.fit_transform(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f4ad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming quiz data\n",
    "quiz = prediction_pipeline.fit_transform(quiz)\n",
    "quiz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b694fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data null count\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2cdd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiz null count\n",
    "quiz.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b226c72e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a35cdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data describe\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2e451f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Unique values\n",
    "data.apply(lambda x: len(x.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ac11d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Seeing correlation between actual_handling_days and delivery_days\n",
    "sns.scatterplot(x='actual_handling_days', y='delivery_days', data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf70e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing correlation between carrier estimate delivery_days\n",
    "# sns.scatterplot(x='carrier_max_estimate', y='delivery_days', data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484c2533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing correlation between weight_lbs and normalized delivery_days\n",
    "# sns.scatterplot(x='weight_lbs', y='delivery_scaled', data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526ebf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing if delivery_days vary between different categories\n",
    "# for i in range(0, 33):\n",
    "#     median = data[data[f'category_id_{i}'] == 1]['delivery_days'].median()\n",
    "#     mean = data[data[f'category_id_{i}'] == 1]['delivery_days'].mean()\n",
    "#     print(f'{i} mean: {mean}, median: {median}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9252090",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Seeing if delivery_days vary between different shipment methods\n",
    "# for i in range(0, 27):\n",
    "#     median = data[data[f'shipment_method_id_{i}'] == 1]['delivery_days'].median()\n",
    "#     mean = data[data[f'shipment_method_id_{i}'] == 1]['delivery_days'].mean()\n",
    "#     print(f'{i} mean: {mean}, median: {median}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17638f23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Seeing if delivery_days vary between shipping distance\n",
    "# data['distance'] = abs(data['item_zip'] - data['buyer_zip'])\n",
    "# for i in range(0, 10):\n",
    "#     median = data[data['distance'] == i]['delivery_days'].median()\n",
    "#     mean = data[data['distance'] == i]['delivery_days'].mean()\n",
    "#     print(f'{i} mean: {mean}, median: {median}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcc5750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing if delivery_days vary between package_size\n",
    "# for i in range(0, 6):\n",
    "#     median = data[data['package_size'] == i]['delivery_days'].median()\n",
    "#     mean = data[data['package_size'] == i]['delivery_days'].mean()\n",
    "#     print(f'{i} mean: {mean}, median: {median}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4d6814",
   "metadata": {},
   "source": [
    "<span><b>Notes From Exploring Data</b></span>\n",
    "<ul>\n",
    "    <li>Need to remove negative days from data <b>[DONE]</b></li>\n",
    "    <li><i>category_id</i> seems to have same similar values between different categories, drop attribute <b>[DONE]</b></li>\n",
    "    <li><i>shipment_id</i> is still useful besides 23-25 (nulls), drop those <b>[DONE]</b></li>\n",
    "    <li><i>delivery_days</i> grows linearly as the difference between zips increases, we can make more specific later since zip code 7XXXX and zip code 3XXXX are neighbros but have a distance of 4 (too far) in my approach, ohe <b>[DONE]</b></li>\n",
    "    <li>Huge outlier in <i>weight_lbs</i>, need to remove <b>[DONE]</b></li>\n",
    "    <li>Way to many 0 values in <i>weight_lbs</i>, need to remove entire feature <b>[DONE]</b></li>\n",
    "    <li><i>package_size</i> takes on similar values besides label 3, which is because I gave null package sizes the median label, can later bucket the sizes but for now will drop feature entirely <b>[DONE]</b></li>\n",
    "    <li><i>carrier_min_estimate/carrier_max_estimate</i> add no new info, will instead use synthetic features called <i>top_bound</i> and <i>bot_bound</i> which will be used as bounds, if a prediction goes past these bounds in either direction, the bound will be used as the prediction instead<b> [DONE]</b></li>\n",
    "<li>Might need to scale features later on <b>[DONE]</b></li>\n",
    "<li> Create one hot encoding from zips 1 time zone away, 2 time zones away, 3 time zones away <b>[DONE]</b></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c294710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving current data\n",
    "#data.to_csv('data_3', index=False)\n",
    "quiz.to_csv('quiz_3', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc6015b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d0b264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading current data\n",
    "dtype = {\n",
    "         'carrier_min_estimate': 'int16',\n",
    "         'carrier_max_estimate': 'int16',\n",
    "         'actual_handling_days': 'int16',\n",
    "         'delivery_days': 'int16',\n",
    "         'timezone_difference': 'int8',\n",
    "         'acceptance_scan_timestamp': 'datetime64',\n",
    "         'min_off_days': 'int16',\n",
    "         'max_off_days': 'int16',\n",
    "        }\n",
    "\n",
    "for i in range(0, 27):\n",
    "    if i in [23, 24, 25]:\n",
    "        continue\n",
    "    dtype[f'shipment_method_id_{i}'] = 'int8'\n",
    "    \n",
    "data = pd.read_csv('data_3', usecols=dtype.keys(), dtype=dtype)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4df4614",
   "metadata": {},
   "source": [
    "# Training Time :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5722e4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Splitting features and labels\n",
    "cols = [\n",
    "        'delivery_days',\n",
    "        'acceptance_scan_timestamp',\n",
    "       ]\n",
    "X = data.drop(columns=cols)\n",
    "cols.pop()\n",
    "y = data.filter(cols)\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edff2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
    "del X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f05aaaf",
   "metadata": {},
   "source": [
    "## Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f270f0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing and choosing models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, HuberRegressor, ElasticNetCV, SGDRegressor, Lasso, ElasticNet\n",
    "models = [\n",
    "          LinearRegression(),\n",
    "          Ridge(),\n",
    "          ElasticNetCV(),\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1665e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick way to test error from different sklearn models\n",
    "def validate(model, N):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred = np.round(y_pred)\n",
    "    \n",
    "    y_pred = pd.DataFrame(data=y_pred, columns=['delivery_days'])\n",
    "    \n",
    "    y_pred['pure'] = y_val['delivery_days'].subtract(y_pred['delivery_days'])\n",
    "    \n",
    "    early_error = 0.4 * (y_pred[y_pred['pure'] <= 0]['pure'].sum())\n",
    "    early_error = abs(early_error)\n",
    "    late_error = 0.6 * (y_pred[y_pred['pure'] > 0]['pure'].sum())\n",
    "    \n",
    "    error = (early_error + late_error) / N\n",
    "    error = round(error, 5)\n",
    "    \n",
    "    del y_pred\n",
    "    \n",
    "    print(f'{model}: {error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a1d28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying out models\n",
    "y_val = y_val.reset_index(drop=True)\n",
    "N = y_val.shape[0]\n",
    "for model in models:\n",
    "    validate(model, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1aabf63",
   "metadata": {},
   "source": [
    "<span><b>Notes From Sklearn</b></span>\n",
    "<ul>\n",
    "    <li><i>LinearRegression</i> error without using bound data: .4881, get score for bound data<b> [DONE]</b></li>\n",
    "    <li><i>LinearRegression</i> error on bound approach: .4843, get score for min/max scaled data<b> [DONE]</b></li>\n",
    "    <li><i>LinearRegression</i> error on min/max scaled data doesn't change: .4843, get score for standard scaled data<b> [DONE]</b></li>\n",
    "    <li><i>LinearRegression</i> error on standard scaled data doesn't change: .4843, try neural net<b> [DONE]</b></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4e54ed",
   "metadata": {},
   "source": [
    "## Tensorflow and Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16edd71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data scaling for neural nets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mm_scale = MinMaxScaler()\n",
    "X_train[['actual_handling_days','zip_distance']] = mm_scale.fit_transform(X_train[['actual_handling_days','zip_distance']])\n",
    "y_train['delivery_days'] = y_train['delivery_days'].astype('float32')\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "492c017b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep learning imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2742dc6d",
   "metadata": {},
   "source": [
    "$$custom \\ loss = \\frac{1}{m} \\ [ \\ ( \\ 0.4 \\ * \\sum_{overest.} \\ |y-y'| \\ )+ ( \\ 0.6 \\ * \\sum_{underest.} \\ (y-y') \\ ) \\ ]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a5beff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom loss from eBay\n",
    "def custom_loss(y, y_pred):\n",
    "    y = tf.cast(y, tf.float32)\n",
    "    pure = tf.subtract(y, y_pred)\n",
    "    \n",
    "    over_est = tf.abs(tf.reduce_sum(tf.clip_by_value(pure, clip_value_min=-500, clip_value_max=0)))\n",
    "    under_est = tf.reduce_sum(tf.clip_by_value(pure, clip_value_min=0, clip_value_max=500))\n",
    "    del pure\n",
    "    \n",
    "    return tf.divide(tf.add(tf.multiply(0.4, over_est), tf.multiply(0.6, under_est)), tf.cast(tf.size(y), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b848a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating neural network\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(1, input_shape=X_train.shape[1:]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009b63ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting neural network to data\n",
    "opt = keras.optimizers.SGD(lr=0.01, momentum=0.5)\n",
    "model.compile(optimizer=opt, loss=custom_loss)\n",
    "hist = model.fit(X_train, y_train, batch_size=400, epochs=1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5e1360",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Saving model weights\n",
    "model.save_weights('./checkpoints/my_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f0fc73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluating on test set\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5563fa",
   "metadata": {},
   "source": [
    "<span><b>Notes From TF / Keras</b></span>\n",
    "<ul>\n",
    "    <li><i>Neural Network</i> MAE doesn't go below .95, create custom_loss using eBay function<b> [DONE] </b></li>\n",
    "    <li><i>Neural Network</i> custom_loss slows around .49, tune optimizer for speed<b> [DONE] </b></li>\n",
    "    <li><i>Neural Network</i> accidentally included bounds, val loss is way better, check val loss without scaling actual_handling_days and zip_distance<b> [DONE] </b></li>\n",
    "    <li><i>Neural Network</i> loss is better with bigger batch_size, try increasing and checking<b> [DONE] </b></li>\n",
    "    <li>Check if <i>Neural Network</i> loss is better with bounds as features, it is not, drop features<b> [DONE] </b></li>\n",
    "    <li><i>Neural Network</i> loss is not any better with OHE zips, bin into time zones assuming that on average if source and destination are in the same time zone, faster delivery<b> [DONE] </b></li>\n",
    "    <li><i>Neural Network</i> loss is better with shipment id than without, find more clever features from the timestamps, and only carrier_min_estimate, carrier_max_estimate can be revived as a relevant feature, for example the estimates are probably only business days, so add weekends and holidays count between estimate and acceptance date as features more accuracy<b> [DONE] </b></li>\n",
    "    <li> Figure out the best layers in order to output less loss on <i>Neural Network</i><b> [ND] </b></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cc7e06",
   "metadata": {},
   "source": [
    "# Output Center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65bef2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e924836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading quiz\n",
    "dtype = {\n",
    "        'acceptance_scan_timestamp': 'object',\n",
    "        'carrier_min_estimate': 'int16',\n",
    "        'carrier_max_estimate': 'int16',\n",
    "        'actual_handling_days': 'int8',\n",
    "        'payment_datetime': 'object',\n",
    "        'timezone_difference': 'int8',\n",
    "        'min_off_days': 'int8',\n",
    "        'max_off_days': 'int8',\n",
    "       }\n",
    "\n",
    "for i in range(0, 19):\n",
    "    dtype[f'shipment_method_id_{i}'] = 'int8'\n",
    "    \n",
    "quiz = pd.read_csv('quiz_3', usecols=dtype.keys(), dtype=dtype)\n",
    "\n",
    "submission = quiz['payment_datetime']\n",
    "submission = pd.DataFrame(data=submission, columns=['payment_datetime'])\n",
    "\n",
    "quiz.drop(columns=['payment_datetime', 'acceptance_scan_timestamp'], inplace=True)\n",
    "for i in range(26, 18, -1):\n",
    "    if i in [23, 25]:\n",
    "        continue\n",
    "    quiz.insert(22, f'shipment_method_id_{i}', 0)\n",
    "    quiz[f'shipment_method_id_{i}'] = quiz[f'shipment_method_id_{i}'].astype('int8')\n",
    "    \n",
    "submission['payment_datetime'] = pd.to_datetime(submission['payment_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb1e239c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating neural network\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(1, input_shape=quiz.shape[1:]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e43e3ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x25e0ec7bf70>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading weights from training data\n",
    "model.load_weights('./checkpoints/my_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44fa11b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting prediction as day into dataframe\n",
    "pred = model.predict(quiz)\n",
    "pred = np.around(pred)\n",
    "pred = pred.astype(int)\n",
    "submission['pred'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "857c2ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting prediction as a date\n",
    "temp = submission['pred'].apply(lambda x: pd.Timedelta(x, unit='D'))\n",
    "submission['pred'] = submission['payment_datetime'] + temp\n",
    "submission.drop(columns=['payment_datetime'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9edd15ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading record number\n",
    "records = pd.read_csv('quiz.tsv', sep='\\t', usecols=['record_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7aac829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting predictions\n",
    "records['predicted_delivery_date'] = submission['pred']\n",
    "del submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64a21f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting\n",
    "records.to_csv('submission_2', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507e5c62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
